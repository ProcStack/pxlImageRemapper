# pxlImageRemapper :: v0.0.1
### Small batch VAE & Diffusion model training/generation
&nbsp;
### What's it do?
Train a model from the ground up on your own images and labels.
<br/>&nbsp;

### It doesn't do what I just said yet
If you run the correct sections of code in the right order, it does, but I just made this thing's gui
<br/>&nbsp;

### Purpose?
Written to visualize how VAE encoders and decoders learn from training material, along with how Diffusion models generate.
<br/>&nbsp; While training on your own images and labels.

*Note*:
<br/>Generation doesn't work yet through the gui.  Should be working shortly.
<br/>&nbsp; This project just launched.
<br/>&nbsp;

---

### Header ripped from `main.py`
Diffusion models exist... Why is this a thing?     
&nbsp; More of a learning experience than anything else.

Visualize how ai's learn latent space encodings and can be used to generate your own ai images.      
With custom levels of training and generation,
<br/>&nbsp; You can create your own unique images based on the specfic labels your model is trained on.     

Should you have a collection of images you want to create a custom stand-alone model for,
<br/>&nbsp; This is a good place to start for that!        
<br/>If not, I provided a sample set of hand written letters to get you started.
<br/>&nbsp; You can find them in `./input`

---
